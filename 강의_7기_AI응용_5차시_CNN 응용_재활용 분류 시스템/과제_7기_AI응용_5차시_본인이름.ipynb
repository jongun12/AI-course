{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "문항 1. CNN의 핵심 특징 강의에서 다룬 CNN(합성곱 신경망)이 기존의 완전 연결 신경망(DNN)보다 이미지 처리에 강력한 성능을 보이는 3가지 주요 특징이 있습니다. 가중치 공유(Weight Sharing) 외에 나머지 두 가지 특징을 서술하세요."
      ],
      "metadata": {
        "id": "prw9ZuYhDlAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "답변 작성란:\n",
        "\n",
        "가중치 공유 (Weight Sharing)\n",
        "\n",
        "( )\n",
        "\n",
        "( )"
      ],
      "metadata": {
        "id": "1mmz4pjrDqmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문항 2. 전이 학습 (Transfer Learning) ImageNet과 같은 대규모 데이터셋으로 미리 학습된 모델(Pre-trained Model)의 가중치를 가져와서, 새로운 데이터셋이나 문제에 맞게 재학습시키는 기법을 무엇이라고 합니까? 또한 이 기법을 사용할 때의 장점을 한 가지 서술하세요."
      ],
      "metadata": {
        "id": "2lcsnkn4DqjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "답변 작성란:\n",
        "\n",
        "용어:\n",
        "\n",
        "장점:"
      ],
      "metadata": {
        "id": "dRfVOOqdDqYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문항 3. LeNet 모델 정의 - 합성곱 층 (Convolution Layers) LeNet-5 구조를 기반으로 한 LeNet 클래스의 __init__ 메서드입니다. 주석에 명시된 입출력 채널 수와 커널 크기에 맞춰 **합성곱 층(self.cn1, self.cn2)** 을 정의하는 코드를 작성하세요."
      ],
      "metadata": {
        "id": "xrdSbG50DqVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        # TODO: 첫 번째 합성곱 층 정의\n",
        "        # 입력 채널: 3 (RGB), 출력 채널: 6, 커널 크기: 5x5\n",
        "        self.cn1 = # (코드를 입력하세요)\n",
        "\n",
        "        # TODO: 두 번째 합성곱 층 정의\n",
        "        # 입력 채널: 6, 출력 채널: 16, 커널 크기: 5x5\n",
        "        self.cn2 = # (코드를 입력하세요)\n",
        "\n",
        "        # 완전 연결 층 정의 (이어서 작성할 문제)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.cn1(x))\n",
        "        x = F.max_pool2d(x, (2, 2))\n",
        "        x = F.relu(self.cn2(x))\n",
        "        x = F.max_pool2d(x, (2, 2))\n",
        "        x = x.view(-1, self.flattened_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def flattened_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_feats = 1\n",
        "        for s in size:\n",
        "            num_feats *= s\n",
        "        return num_feats"
      ],
      "metadata": {
        "id": "9b-E6aN0DqJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "문항 4. LeNet 모델 정의 - 완전 연결 층 (Fully Connected Layers) 앞서 작성한 합성곱 층을 거친 후 출력되는 특징 맵을 1차원 벡터로 펼친 뒤, 분류를 수행하는 **완전 연결 층(self.fc1, self.fc2, self.fc3)** 을 정의하세요."
      ],
      "metadata": {
        "id": "sJuhFkMEDqG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet_Part2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet_Part2, self).__init__()\n",
        "        self.cn1 = nn.Conv2d(3, 6, 5)\n",
        "        self.cn2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # TODO: 완전 연결 층 정의\n",
        "        # fc1: 입력 16*5*5 -> 출력 120\n",
        "        self.fc1 = # (코드를 입력하세요)\n",
        "\n",
        "        # fc2: 입력 120 -> 출력 84\n",
        "        self.fc2 = # (코드를 입력하세요)\n",
        "\n",
        "        # fc3: 입력 84 -> 출력 10 (CIFAR-10 클래스 개수)\n",
        "        self.fc3 = # (코드를 입력하세요)"
      ],
      "metadata": {
        "id": "ldLWuNtHDp26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "문항 5. 학습 루프 구현 (Training Loop) 모델 학습의 핵심 단계인 **역전파(Backpropagation)** 와 가중치 업데이트(Optimization) 과정을 구현하세요. (Optimizer는 optim, 손실 함수 결과는 loss 변수에 저장되어 있다고 가정합니다.)"
      ],
      "metadata": {
        "id": "0Ly2KfP_Dp0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, trainloader, optim, epoch):\n",
        "    loss_total = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        ip, ground_truth = data\n",
        "\n",
        "        # TODO: 1. 변화도(Gradient) 초기화\n",
        "        # (코드를 입력하세요)\n",
        "\n",
        "        # 순전파 및 손실 계산\n",
        "        op = net(ip)\n",
        "        loss = nn.CrossEntropyLoss()(op, ground_truth)\n",
        "\n",
        "        # TODO: 2. 역전파 (Backpropagation) 수행\n",
        "        # (코드를 입력하세요)\n",
        "\n",
        "        # TODO: 3. 가중치 업데이트 (Optimization) 수행\n",
        "        # (코드를 입력하세요)\n",
        "\n",
        "        loss_total += loss.item()\n",
        "        if (i+1) % 1000 == 0:\n",
        "            print(f'[Epoch: {epoch+1}, Mini-batches: {i+1}] loss: {loss_total/200:.3f}')\n",
        "            loss_total = 0.0"
      ],
      "metadata": {
        "id": "GeMGib5GDpai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "문항 6. 모델 평가 및 예측 (Prediction) 테스트 데이터에 대해 모델의 성능을 평가할 때, 모델의 출력값(op) 중에서 가장 높은 확률을 가진 클래스의 인덱스를 찾아야 합니다. torch.max 함수를 사용하여 **예측 클래스(pred)** 를 구하는 코드를 작성하세요."
      ],
      "metadata": {
        "id": "-YoNOT7eDpVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net, testloader):\n",
        "    success = 0\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            im, ground_truth = data\n",
        "            op = net(im)\n",
        "\n",
        "            # TODO: 예측값 구하기 (가장 높은 값을 가진 인덱스 추출)\n",
        "            # 힌트: torch.max(tensor, dim) 사용\n",
        "            _, pred = # (코드를 입력하세요)\n",
        "\n",
        "            counter += ground_truth.size(0)\n",
        "            success += (pred == ground_truth).sum().item()\n",
        "\n",
        "    print(f'Accuracy: {100 * success / counter}%')"
      ],
      "metadata": {
        "id": "kDsbUq19Do7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}