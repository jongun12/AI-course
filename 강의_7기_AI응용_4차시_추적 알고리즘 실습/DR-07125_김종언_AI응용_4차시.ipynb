{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtO_avHUCkPr"
   },
   "source": [
    "문항 1. MeanShift와 CamShift의 차이점 MeanShift 알고리즘은 데이터의 밀도가 가장 높은 곳으로 윈도우를 이동시키며 객체를 추적하지만, 윈도우의 크기가 고정되어 있다는 단점이 있습니다. 이를 개선하여 객체의 크기와 회전 변화에 따라 윈도우의 크기와 방향을 동적으로 조절할 수 있게 만든 알고리즘의 이름은 무엇입니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dglk01ErCmbB"
   },
   "source": [
    "답변 작성란: CamShift 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDXyz9PrCnVg"
   },
   "source": [
    "문항 2. 템플릿 매칭(Template Matching) 작은 이미지(템플릿)를 큰 이미지(원본) 위에서 이동시키며 가장 유사한 부분을 찾는 기법을 템플릿 매칭이라고 합니다. OpenCV의 cv2.matchTemplate 함수를 사용하면 결과로 **유사도 맵(2차원 배열)** 이 나옵니다. 이 결과 행렬에서 최댓값(가장 유사한 위치)의 좌표를 찾기 위해 사용하는 OpenCV 함수는 무엇입니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2a7CFexCndv"
   },
   "source": [
    "답변 작성란: cv2.minMaxLoc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGPwUxebCnnl"
   },
   "source": [
    "문항 3. 배경 제거 (Background Subtraction) 구현 CCTV 영상 등에서 고정된 배경을 제거하고 움직이는 객체만 추출하기 위해 배경 제거 알고리즘을 사용합니다. 제공된 실습 파일(background.py)을 참고하여 MOG(Mixture of Gaussians) 알고리즘 객체를 생성하고, 마스크를 추출하는 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g80cyZcICnrE"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture('newyork.mp4') # 실습용 비디오 파일\n",
    "\n",
    "# TODO: MOG 배경 제거 객체 생성 (cv2.bgsegm 모듈 사용)\n",
    "# (OpenCV 버전에 따라 cv2.createBackgroundSubtractorMOG2()를 쓰기도 하지만,\n",
    "# 강의 코드인 cv2.bgsegm.createBackgroundSubtractorMOG()를 사용하세요)\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # TODO: 프레임에 배경 제거 적용하여 마스크(fgmask) 생성\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # cv2.imshow('Original', frame)\n",
    "    # cv2.imshow('MOG Mask', fgmask)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmoubIwsCn0T"
   },
   "source": [
    "문항 4. 템플릿 매칭 (Template Matching) game.jpg 화면에서 coin.png 아이템의 위치를 찾으려 합니다. cv2.matchTemplate을 사용하여 매칭을 수행하고, 가장 유사도가 높은 위치(Top-Left)를 찾는 코드를 완성하세요.\n",
    "\n",
    "(매칭 메서드는 cv2.TM_CCOEFF_NORMED를 사용합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JU4DVhTCn3k"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('game.jpg')\n",
    "template = cv2.imread('coin.png')\n",
    "\n",
    "# TODO: 템플릿 매칭 수행\n",
    "res = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED)# (코드를 입력하세요: img, template, method 순서)\n",
    "\n",
    "# TODO: 매칭 결과에서 최소/최대 값과 위치 찾기\n",
    "min_val, max_val, min_loc, max_loc = # (코드를 입력하세요)\n",
    "\n",
    "# TM_CCOEFF_NORMED는 최대값이 가장 유사한 지점임\n",
    "top_left = max_loc\n",
    "print(f\"Detected Location: {top_left}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EZAgK8wCr77"
   },
   "source": [
    "문항 5. 추적을 위한 히스토그램 역투영 (Backprojection) MeanShift나 CamShift를 사용하기 위해서는 먼저 추적할 대상(ROI)의 색상 히스토그램을 구하고, 전체 영상에서 해당 색상 분포를 가진 영역을 확률로 표현하는 역투영(Backprojection) 과정이 필요합니다. 아래 코드를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAqRmFvzCr4H"
   },
   "outputs": [],
   "source": [
    "# roi: 추적할 객체 이미지 (HSV 색공간)\n",
    "# frame_hsv: 현재 프레임 (HSV 색공간)\n",
    "\n",
    "# 1. ROI의 히스토그램 계산 (Hue 채널만 사용: [0], 범위: [0, 180])\n",
    "roi_hist = cv2.calcHist([roi], [0], None, [180], [0, 180])\n",
    "\n",
    "# 2. 히스토그램 정규화 (0~255 범위로)\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# TODO: 현재 프레임(frame_hsv)에 히스토그램 역투영 적용\n",
    "# 인자: [이미지], [채널], 히스토그램, [범위], scale\n",
    "dst = cv2.calcBackProject([frame_hsv],[0],roi_hist,[0,180],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbMd3tIYCrt0"
   },
   "source": [
    "문항 6. Lucas-Kanade Optical Flow 이전 프레임의 코너점(prev_pts)들이 현재 프레임(curr_frame)에서 어디로 이동했는지 추적하려 합니다. OpenCV의 피라미드 기반 루카스-카나데(Lucas-Kanade) 함수를 사용하여 next_pts를 구하는 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCLccMPQCrUR"
   },
   "outputs": [],
   "source": [
    "# prev_gray: 이전 프레임 (Gray)\n",
    "# gray: 현재 프레임 (Gray)\n",
    "# prev_pts: 추적할 특징점들 (numpy array)\n",
    "\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# TODO: Lucas-Kanade Optical Flow 계산\n",
    "# 반환값: next_pts(이동한 좌표), status(성공여부), err(오차)\n",
    "next_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray,gray,prev_pts,None)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN6IuubnZi17wXSmBQOu6nc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
